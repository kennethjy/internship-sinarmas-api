{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7cb51d-3ef8-4ddd-a0d3-e919db01ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "packages = [\"transformers\", \"datasets\", \"torch\", \"torchvision\", \"PIL\", \"accelerate\"]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "        print(f\"{package} is installed ‚úÖ\")\n",
    "    except ImportError:\n",
    "        print(f\"{package} is NOT installed ‚ùå\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb950340-af72-4af3-b93a-acd5c2e04249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function to check if a path exists\n",
    "def check_path_exists(path):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"The path '{path}' exists.\")\n",
    "    else:\n",
    "        print(f\"The path '{path}' does not exist.\")\n",
    "\n",
    "# Example usage\n",
    "path_to_check = \"color_img\"\n",
    "check_path_exists(path_to_check)\n",
    "path_to_check = \"pixel_values\"\n",
    "check_path_exists(path_to_check)\n",
    "path_to_check = \"color_images_metadata.json\"\n",
    "check_path_exists(path_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7301c2-d7e7-49be-9e74-7ae5a8e50f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© pixel_values_74.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_98.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_4.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_67.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_96.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_38.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_14.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_18.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_93.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_2.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_32.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_99.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_24.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_69.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_22.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_13.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_33.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_27.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_31.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_29.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_59.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_44.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_83.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_19.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_78.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_1.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_42.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_15.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_7.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_90.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_34.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_73.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_76.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_16.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_6.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_53.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_75.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_41.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_17.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_45.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_63.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_64.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_87.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_5.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_61.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_85.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_50.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_94.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_23.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_79.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_12.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_46.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_88.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_26.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_55.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_8.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_89.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_36.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_30.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_49.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_9.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_62.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_11.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_54.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_39.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_81.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_28.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_21.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_43.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_57.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_35.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_68.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_77.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_100.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_65.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_58.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_25.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_56.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_40.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_52.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_10.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_95.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_70.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_92.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_66.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_80.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_86.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_60.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_47.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_82.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_97.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_72.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_48.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_20.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_3.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_84.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_37.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_71.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_51.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "üß© pixel_values_91.json - pixel_values shape: torch.Size([3, 224, 224]), dtype: torch.float32\n",
      "‚úÖ JSON data loaded successfully!\n",
      "‚úÖ Tokenizer initialized successfully!\n",
      "‚úÖ All labels tokenized and combined into tensor!\n",
      "Libraries imported and configurations set\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries and Configuration\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoProcessor, AutoTokenizer, AutoModelForImageTextToText, Trainer, TrainingArguments\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"  \n",
    "\n",
    "# === Fixing image tensors should be of type torch.float32 ===\n",
    "\n",
    "folder_path = 'pixel_values'\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            pixel_values = np.array(json.load(file))\n",
    "            pixel_values = torch.tensor(pixel_values).float()  # <-- Convert to float32 here\n",
    "            \n",
    "        print(f\"üß© {filename} - pixel_values shape: {pixel_values.shape}, dtype: {pixel_values.dtype}\")\n",
    "\n",
    "# === Load JSON Data ===\n",
    "with open('color_images_metadata.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"‚úÖ JSON data loaded successfully!\")\n",
    "\n",
    "# === Initialize Tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "print(\"‚úÖ Tokenizer initialized successfully!\")\n",
    "\n",
    "# === Tokenize All Labels and Combine Into Tensor ===\n",
    "labels_list = []  # Store all tokenized labels\n",
    "\n",
    "# Loop through all entries in the JSON\n",
    "for item in data:\n",
    "    description = item[\"labels\"][\"description\"]\n",
    "    qa_pairs = \" \".join([f\"{qa['question']} {qa['answer']}\" for qa in item[\"labels\"][\"QA_pairs\"]])\n",
    "    labels_text = f\"Description: {description} QA: {qa_pairs}\"\n",
    "\n",
    "    # Tokenize each label with max_length and padding\n",
    "    label = tokenizer(\n",
    "        labels_text, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=\"max_length\",    # ‚úÖ Ensures all sequences have the same length\n",
    "        truncation=True,\n",
    "        max_length=30            # ‚úÖ Adjust based on the longest sequence\n",
    "    )[\"input_ids\"]\n",
    "    labels_list.append(label)\n",
    "\n",
    "# Stack all labels into a single tensor\n",
    "labels = torch.cat(labels_list, dim=0)\n",
    "\n",
    "print(\"‚úÖ All labels tokenized and combined into tensor!\")\n",
    "\n",
    "\n",
    "# === CONFIGURATION VARIABLES ===\n",
    "# Remember to use the updated paths. I messed up the size, generating 214 instead of 224...\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "JSON_PATH = \"color_images_metadata.json\"  \n",
    "IMAGE_DIR = \"color_img\"                  \n",
    "PIXEL_VALUES_DIR = \"pixel_values\"         \n",
    "OUTPUT_DIR = \"./qwen2.5_vl_finetuned\"\n",
    "LOG_DIR = \"./logs\"\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 5e-5\n",
    "EPOCHS = 1\n",
    "SAVE_LIMIT = 2\n",
    "USE_FP16 = True\n",
    "PUSH_TO_HUB = False\n",
    "SEED = 42\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "print(\"Libraries imported and configurations set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "238b68e3-a819-4854-97cb-d8250546c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labels loaded: 100\n",
      "Labels tensor shape: torch.Size([100, 30])\n",
      "Labels dtype: torch.int64\n",
      "\n",
      "üî¢ Entry 1 - Labels as Token IDs:\n",
      "tensor([  5009,     25,   1096,    374,    264,   6437,   4158,   1894,   2168,\n",
      "            13,  65908,     25,   2160,    419,   1894,   4158,     30,   7414,\n",
      "          2160,    419,   1894,   1045,   1008,   1894,     30,   2308, 151643,\n",
      "        151643, 151643, 151643])\n",
      "üìù Decoded Text:\n",
      "Description: This is a solid white color image. QA: Is this color white? Yes Is this color some other color? No\n",
      "\n",
      "üî¢ Entry 2 - Labels as Token IDs:\n",
      "tensor([  5009,     25,   1096,    374,    264,   6437,   4878,  16576,   1894,\n",
      "          2168,     13,  65908,     25,   2160,    419,   1894,   4878,  16576,\n",
      "            30,   7414,   2160,    419,   1894,   1045,   1008,   1894,     30,\n",
      "          2308, 151643, 151643])\n",
      "üìù Decoded Text:\n",
      "Description: This is a solid magenta color image. QA: Is this color magenta? Yes Is this color some other color? No\n",
      "\n",
      "üî¢ Entry 3 - Labels as Token IDs:\n",
      "tensor([  5009,     25,   1096,    374,    264,   6437,   4878,  16576,   1894,\n",
      "          2168,     13,  65908,     25,   2160,    419,   1894,   4878,  16576,\n",
      "            30,   7414,   2160,    419,   1894,   1045,   1008,   1894,     30,\n",
      "          2308, 151643, 151643])\n",
      "üìù Decoded Text:\n",
      "Description: This is a solid magenta color image. QA: Is this color magenta? Yes Is this color some other color? No\n",
      "\n",
      "üî¢ Entry 4 - Labels as Token IDs:\n",
      "tensor([  5009,     25,   1096,    374,    264,   6437,  18217,   1894,   2168,\n",
      "            13,  65908,     25,   2160,    419,   1894,  18217,     30,   7414,\n",
      "          2160,    419,   1894,   1045,   1008,   1894,     30,   2308, 151643,\n",
      "        151643, 151643, 151643])\n",
      "üìù Decoded Text:\n",
      "Description: This is a solid pink color image. QA: Is this color pink? Yes Is this color some other color? No\n",
      "\n",
      "üî¢ Entry 5 - Labels as Token IDs:\n",
      "tensor([  5009,     25,   1096,    374,    264,   6437,  24932,   1894,   2168,\n",
      "            13,  65908,     25,   2160,    419,   1894,  24932,     30,   7414,\n",
      "          2160,    419,   1894,   1045,   1008,   1894,     30,   2308, 151643,\n",
      "        151643, 151643, 151643])\n",
      "üìù Decoded Text:\n",
      "Description: This is a solid purple color image. QA: Is this color purple? Yes Is this color some other color? No\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Debug Prints\n",
    "print(f\"Total labels loaded: {len(labels_list)}\")\n",
    "print(f\"Labels tensor shape: {labels.shape}\")\n",
    "print(f\"Labels dtype: {labels.dtype}\")\n",
    "\n",
    "# Cell 6: Print the First 5 Labels\n",
    "for i in range(min(5, len(labels))):\n",
    "    print(f\"\\nüî¢ Entry {i + 1} - Labels as Token IDs:\")\n",
    "    print(labels[i])\n",
    "\n",
    "    decoded_labels = tokenizer.decode(labels[i], skip_special_tokens=True)\n",
    "    print(\"üìù Decoded Text:\")\n",
    "    print(decoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280d7c61-5555-4004-a99b-ae3b5366f380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values dtype: torch.float32\n",
      "labels dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"pixel_values dtype: {pixel_values.dtype}\")\n",
    "print(f\"labels dtype: {labels.dtype if 'labels' in locals() else 'No labels'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0107c0c-664b-42cc-b03c-f8a266199be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed has been set. Check the Configuration cell to adjust\n"
     ]
    }
   ],
   "source": [
    "# Set fixed Seed\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "print(\"Seed has been set. Check the Configuration cell to adjust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f166253-7e50-403e-a5c7-026b1ca8af6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values dtype: torch.float32\n",
      "labels dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "class ColorImageDataset(Dataset):\n",
    "    def __init__(self, json_path, processor):\n",
    "        print(\"üîÑ Loading dataset...\")\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "        self.processor = processor\n",
    "        self.qa_pairs = []\n",
    "\n",
    "        # Use updated file paths\n",
    "        for item in self.data:\n",
    "            # Correct file paths\n",
    "            img_path = item[\"file_link\"].replace(\"model_input_test/color_img/\", \"color_img_resized/\")\n",
    "            pixel_values_path = item[\"pixel_values_link\"].replace(\"model_input_test/pixel_values/\", \"pixel_values_resized/\")\n",
    "            \n",
    "            # ‚úÖ Ensure labels exist\n",
    "            if \"labels\" not in item:\n",
    "                print(f\"‚ùó Warning: Missing 'labels' in item {item['index_num']}\")\n",
    "                continue\n",
    "\n",
    "            # Access labels: description and QA pairs\n",
    "            description = item[\"labels\"][\"description\"]\n",
    "            for qa in item[\"labels\"][\"QA_pairs\"]:\n",
    "                question = qa[\"question\"]\n",
    "                answer = qa[\"answer\"]\n",
    "                self.qa_pairs.append((img_path, pixel_values_path, description, question, answer))\n",
    "\n",
    "        print(f\"‚úÖ Dataset loaded with {len(self.qa_pairs)} QA pairs.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.qa_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, pixel_values_path, description, question, answer = self.qa_pairs[idx]\n",
    "\n",
    "        # Debug prints to confirm paths\n",
    "        print(\"üîç Loading image from:\", img_path)\n",
    "        print(\"üîç Loading pixel values from:\", pixel_values_path)\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Load pixel values\n",
    "        with open(pixel_values_path, 'r') as f:\n",
    "            pixel_values = json.load(f)\n",
    "\n",
    "        # ‚úÖ Debug: Print description and question\n",
    "        print(\"üìù Description:\", description)\n",
    "        print(\"‚ùì Question:\", question)\n",
    "        print(\"üí¨ Answer:\", answer)\n",
    "\n",
    "        # Encode input using Qwen processor\n",
    "        inputs = self.processor(\n",
    "            images=image,\n",
    "            text=[f\"Image Description: {description}\\nQuestion: {question}\"],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # ‚úÖ Debug: Check processor output\n",
    "        print(\"üì¶ Processor output keys:\", inputs.keys())\n",
    "\n",
    "        # Tokenize the expected answer\n",
    "        labels = self.processor.tokenizer(\n",
    "            answer, \n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # ‚úÖ Ensure labels exist and are within range\n",
    "        vocab_size = self.processor.tokenizer.vocab_size\n",
    "        if \"input_ids\" in labels and (labels[\"input_ids\"] < vocab_size).all() and (labels[\"input_ids\"] >= 0).all():\n",
    "            inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "            print(\"üè∑Ô∏è Final labels dtype:\", inputs[\"labels\"].dtype)\n",
    "            print(f\"üè∑Ô∏è labels tensor shape: {inputs['labels'].shape}\")\n",
    "        else:\n",
    "            print(\"‚ùó Warning: Labels out of range or missing 'input_ids'\")\n",
    "\n",
    "        # ‚úÖ Convert pixel values to tensor\n",
    "        pixel_tensor = torch.tensor(pixel_values, dtype=torch.float32)\n",
    "\n",
    "        # ‚úÖ Ensure correct shape for model input\n",
    "        pixel_tensor = pixel_tensor.view(3, 224, 224)  # Standard RGB format\n",
    "        pixel_tensor = pixel_tensor.unsqueeze(0)  # Ensure batch dimension (1, 3, 224, 224)\n",
    "        print(f\"üìè pixel_values tensor shape: {pixel_tensor.shape}\")\n",
    "\n",
    "        inputs[\"pixel_values\"] = pixel_tensor\n",
    "\n",
    "        # ‚úÖ Add image_grid_thw required by Qwen2_5_VL\n",
    "        inputs[\"image_grid_thw\"] = torch.tensor([16, 16, 3], dtype=torch.int64)\n",
    "\n",
    "        # ‚úÖ Return final inputs\n",
    "        return {key: val.squeeze(0) if isinstance(val, torch.Tensor) and key != \"pixel_values\" else val for key, val in inputs.items()}\n",
    "\n",
    "\n",
    "print(f\"pixel_values dtype: {pixel_values.dtype}\")\n",
    "print(f\"labels dtype: {labels.dtype if 'labels' in locals() else 'No labels'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750c1e7c-9efb-4fb3-96eb-d39d4865dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading model and processor from cache...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b5a90c981f4001b7d808db88350cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model and processor loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load Model and Processor\n",
    "print(\"üîÑ Loading model and processor from cache...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, local_files_only=True)\n",
    "model = AutoModelForImageTextToText.from_pretrained(MODEL_NAME, local_files_only=True)\n",
    "print(\"‚úÖ Model and processor loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c86319-53eb-44dd-b5b1-ce0e9b0117d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # ‚úÖ Extract individual items from the batch\n",
    "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])  # Batch pixel values\n",
    "    image_grid_thw = torch.stack([item[\"image_grid_thw\"] for item in batch])  # Batch image grid\n",
    "\n",
    "    # ‚úÖ Handle variable-length labels using padding\n",
    "    labels = [item[\"labels\"] for item in batch if \"labels\" in item]\n",
    "    if labels:\n",
    "        # Use pad_sequence to pad labels to the longest sequence in the batch\n",
    "        from torch.nn.utils.rnn import pad_sequence\n",
    "        labels = pad_sequence(labels, batch_first=True, padding_value=-100)  # Use -100 for ignored tokens\n",
    "    else:\n",
    "        labels = None\n",
    "\n",
    "    # ‚úÖ Combine into a dictionary\n",
    "    batch_dict = {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"image_grid_thw\": image_grid_thw,\n",
    "    }\n",
    "\n",
    "    if labels is not None:\n",
    "        batch_dict[\"labels\"] = labels\n",
    "\n",
    "    return batch_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07d68c96-32d7-4cb1-b2d8-7c7f90b369b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading dataset...\n",
      "‚úÖ Dataset loaded with 200 QA pairs.\n",
      "‚úÖ Dataset split: 160 training samples, 40 validation samples.\n",
      "üîç Loading image from: color_img/color_img_94.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_94.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_18.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_18.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color brown?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_38.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_38.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color lime?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_48.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_48.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_81.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_81.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_24.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_24.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_82.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_82.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color purple?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_59.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_59.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üî• Train Batch pixel_values shape: torch.Size([8, 1, 3, 224, 224])\n",
      "üî• Train Batch labels shape: torch.Size([8, 1])\n",
      "üîç Loading image from: color_img/color_img_2.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_2.json\n",
      "üìù Description: This is a solid magenta color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_40.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_40.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color white?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_78.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_78.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_13.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_13.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color cyan?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_80.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_80.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color blue?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_73.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_73.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color blue?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_58.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_58.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color lime?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_90.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_90.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color yellow?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üî• Validation Batch pixel_values shape: torch.Size([8, 1, 3, 224, 224])\n",
      "üî• Validation Batch labels shape: torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Load full dataset\n",
    "train_dataset = ColorImageDataset(\"color_images_metadata.json\", processor)\n",
    "\n",
    "# ‚úÖ Split into training and validation datasets (80/20 split)\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"‚úÖ Dataset split: {len(train_dataset)} training samples, {len(val_dataset)} validation samples.\")\n",
    "\n",
    "# ‚úÖ Ensure DataLoader maintains batch dimension (Training)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn  # Use custom collate_fn\n",
    ")\n",
    "\n",
    "# ‚úÖ Ensure DataLoader maintains batch dimension (Validation)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,  # No need to shuffle validation data\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# ‚úÖ Debug: Check one batch from training and validation\n",
    "for batch in train_loader:\n",
    "    print(f\"üî• Train Batch pixel_values shape: {batch['pixel_values'].shape}\")\n",
    "    print(f\"üî• Train Batch labels shape: {batch['labels'].shape if 'labels' in batch else 'No labels'}\")\n",
    "    break\n",
    "\n",
    "for batch in val_loader:\n",
    "    print(f\"üî• Validation Batch pixel_values shape: {batch['pixel_values'].shape}\")\n",
    "    print(f\"üî• Validation Batch labels shape: {batch['labels'].shape if 'labels' in batch else 'No labels'}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6a8a012-4770-4787-8768-84eca28646d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configurations set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capstone_student/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training Configuration\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    logging_dir=LOG_DIR,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=SAVE_LIMIT,\n",
    "    push_to_hub=PUSH_TO_HUB,\n",
    "    fp16=USE_FP16,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "print(\"Training configurations set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "323f8af1-cdcc-4181-965a-4f6ad843053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 151643\n",
      "üîç Loading image from: color_img/color_img_31.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_31.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color black?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 1 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_24.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_24.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color pink?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 2 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_39.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_39.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color lime?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 3 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_93.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_93.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color cyan?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 4 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_72.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_72.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color lime?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 5 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_15.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_15.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 6 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_38.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_38.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 7 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_95.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_95.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 8 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_57.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_57.json\n",
      "üìù Description: This is a solid green color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 9 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_71.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_71.json\n",
      "üìù Description: This is a solid magenta color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 10 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_46.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_46.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 11 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_15.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_15.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color pink?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 12 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_57.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_57.json\n",
      "üìù Description: This is a solid green color image.\n",
      "‚ùì Question: Is this color green?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 13 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_83.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_83.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 14 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_20.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_20.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 15 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_77.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_77.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color blue?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 16 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_42.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_42.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 17 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_76.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_76.json\n",
      "üìù Description: This is a solid orange color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 18 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_25.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_25.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 19 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_74.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_74.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color black?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 20 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_99.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_99.json\n",
      "üìù Description: This is a solid orange color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 21 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_27.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_27.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 22 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_73.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_73.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 23 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_5.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_5.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 24 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_64.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_64.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color white?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 25 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_47.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_47.json\n",
      "üìù Description: This is a solid green color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 26 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_30.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_30.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color brown?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 27 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_59.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_59.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color black?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 28 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_55.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_55.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 29 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_65.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_65.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 30 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_88.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_88.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color purple?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 31 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_100.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_100.json\n",
      "üìù Description: This is a solid orange color image.\n",
      "‚ùì Question: Is this color orange?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 32 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_46.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_46.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color yellow?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 33 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_21.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_21.json\n",
      "üìù Description: This is a solid turquoise color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 34 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_89.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_89.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color pink?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 35 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_1.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_1.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color white?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 36 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_99.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_99.json\n",
      "üìù Description: This is a solid orange color image.\n",
      "‚ùì Question: Is this color orange?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 37 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_30.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_30.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 38 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_65.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_65.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color cyan?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 39 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_77.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_77.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 40 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_87.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_87.json\n",
      "üìù Description: This is a solid red color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 41 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_20.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_20.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color brown?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 42 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_95.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_95.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color blue?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 43 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_17.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_17.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 44 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_33.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_33.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 45 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_85.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_85.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 46 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_32.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_32.json\n",
      "üìù Description: This is a solid turquoise color image.\n",
      "‚ùì Question: Is this color turquoise?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 47 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_62.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_62.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 48 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_93.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_93.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 49 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_60.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_60.json\n",
      "üìù Description: This is a solid green color image.\n",
      "‚ùì Question: Is this color green?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 50 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_39.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_39.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 51 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_96.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_96.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color cyan?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 52 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_10.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_10.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color white?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 53 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_51.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_51.json\n",
      "üìù Description: This is a solid green color image.\n",
      "‚ùì Question: Is this color green?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 54 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_97.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_97.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 55 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_34.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_34.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 56 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_72.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_72.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 57 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_1.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_1.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 58 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_48.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_48.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 59 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_3.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_3.json\n",
      "üìù Description: This is a solid magenta color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 60 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_49.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_49.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 61 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_9.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_9.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 62 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_35.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_35.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 63 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_52.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_52.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color pink?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 64 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_70.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_70.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 65 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_45.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_45.json\n",
      "üìù Description: This is a solid turquoise color image.\n",
      "‚ùì Question: Is this color turquoise?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 66 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_18.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_18.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color brown?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 67 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_19.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_19.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 68 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_10.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_10.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 69 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_7.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_7.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color yellow?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 70 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_2.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_2.json\n",
      "üìù Description: This is a solid magenta color image.\n",
      "‚ùì Question: Is this color magenta?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 71 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_67.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_67.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 72 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_64.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_64.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 73 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_66.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_66.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 74 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_82.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_82.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color purple?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 75 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_4.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_4.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 76 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_41.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_41.json\n",
      "üìù Description: This is a solid green color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 77 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_91.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_91.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 78 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_63.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_63.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 79 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_52.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_52.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 80 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_26.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_26.json\n",
      "üìù Description: This is a solid orange color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 81 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_27.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_27.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color pink?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 82 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_28.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_28.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color black?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 83 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_55.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_55.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color cyan?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 84 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_71.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_71.json\n",
      "üìù Description: This is a solid magenta color image.\n",
      "‚ùì Question: Is this color magenta?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 85 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_38.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_38.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color lime?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 86 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_28.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_28.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 87 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_24.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_24.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 88 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_9.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_9.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color cyan?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 89 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_98.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_98.json\n",
      "üìù Description: This is a solid orange color image.\n",
      "‚ùì Question: Is this color orange?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 90 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_6.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_6.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color brown?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 91 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_44.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_44.json\n",
      "üìù Description: This is a solid orange color image.\n",
      "‚ùì Question: Is this color orange?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 92 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_79.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_79.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 93 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_11.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_11.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color cyan?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 94 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_70.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_70.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color brown?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 95 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_58.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_58.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 96 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_3.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_3.json\n",
      "üìù Description: This is a solid magenta color image.\n",
      "‚ùì Question: Is this color magenta?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 97 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_84.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_84.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 98 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_74.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_74.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 99 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_13.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_13.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 100 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_23.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_23.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color gray?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 101 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_94.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_94.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color white?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 102 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_53.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_53.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 103 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_79.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_79.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color gray?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 104 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_11.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_11.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 105 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_81.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_81.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 106 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_7.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_7.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 107 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_48.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_48.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color black?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 108 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_23.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_23.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 109 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_25.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_25.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color purple?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 110 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_97.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_97.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color blue?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 111 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_16.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_16.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 112 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_80.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_80.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 113 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_45.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_45.json\n",
      "üìù Description: This is a solid turquoise color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 114 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_67.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_67.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color black?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 115 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_16.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_16.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color black?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 116 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_51.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_51.json\n",
      "üìù Description: This is a solid green color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 117 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_31.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_31.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 118 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_92.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_92.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 119 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_94.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_94.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 120 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_54.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_54.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 121 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_81.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_81.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color gray?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 122 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_100.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_100.json\n",
      "üìù Description: This is a solid orange color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 123 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_53.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_53.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color yellow?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 124 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_59.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_59.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 125 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_8.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_8.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color cyan?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 126 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_36.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_36.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 127 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_22.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_22.json\n",
      "üìù Description: This is a solid magenta color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 128 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_14.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_14.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color yellow?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 129 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_61.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_61.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color lime?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 130 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_96.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_96.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 131 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_50.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_50.json\n",
      "üìù Description: This is a solid green color image.\n",
      "‚ùì Question: Is this color green?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 132 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_43.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_43.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 133 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_86.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_86.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 134 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_91.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_91.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color blue?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 135 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_19.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_19.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color cyan?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 136 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_88.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_88.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 137 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_8.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_8.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 138 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_14.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_14.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 139 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_37.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_37.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color black?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 140 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_63.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_63.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color black?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 141 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_56.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_56.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 142 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_76.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_76.json\n",
      "üìù Description: This is a solid orange color image.\n",
      "‚ùì Question: Is this color orange?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 143 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_75.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_75.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 144 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_34.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_34.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color black?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 145 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_61.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_61.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 146 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_18.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_18.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 147 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_36.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_36.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color white?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 148 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_92.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_92.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color cyan?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 149 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_82.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_82.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 150 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_66.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_66.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color lime?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 151 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_69.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_69.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 152 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_33.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_33.json\n",
      "üìù Description: This is a solid blue color image.\n",
      "‚ùì Question: Is this color blue?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 153 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_54.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_54.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color white?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 154 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_42.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_42.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color gray?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 155 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_56.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_56.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color gray?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 156 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_69.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_69.json\n",
      "üìù Description: This is a solid pink color image.\n",
      "‚ùì Question: Is this color pink?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 157 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_78.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_78.json\n",
      "üìù Description: This is a solid purple color image.\n",
      "‚ùì Question: Is this color purple?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 158 - Labels as Token IDs:\n",
      "tensor([9454])\n",
      "üîç Loading image from: color_img/color_img_32.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_32.json\n",
      "üìù Description: This is a solid turquoise color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 159 - Labels as Token IDs:\n",
      "tensor([2753])\n",
      "üîç Loading image from: color_img/color_img_6.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_6.json\n",
      "üìù Description: This is a solid brown color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "üî¢ Entry 160 - Labels as Token IDs:\n",
      "tensor([2753])\n"
     ]
    }
   ],
   "source": [
    "# Check if label values exceed vocab size\n",
    "vocab_size = tokenizer.vocab_size\n",
    "print(\"Tokenizer vocab size:\", vocab_size)\n",
    "\n",
    "# Debug the first batch of labels\n",
    "for i, batch in enumerate(train_dataset):\n",
    "    labels = batch[\"labels\"]\n",
    "    print(f\"\\nüî¢ Entry {i + 1} - Labels as Token IDs:\")\n",
    "    print(labels)\n",
    "\n",
    "    # Ensure labels are within vocab range\n",
    "    if (labels >= vocab_size).any():\n",
    "        print(f\"‚ùó Warning: Labels exceed vocab size in entry {i + 1}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2397caf7-96f6-4e11-9aa2-ee50a159b779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Initializing trainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_257495/2149996427.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-25 13:39:58,604] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Trainer Initalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capstone_student/miniconda3/compiler_compat/ld: warning: librt.so.1, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: warning: libpthread.so.0, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: warning: libstdc++.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: warning: libm.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::runtime_error::~runtime_error()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__gxx_personality_v0@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::tellp()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::steady_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for bool@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_logic_error(char const*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::logic_error@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::~locale()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_end_catch@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::logic_error::~logic_error()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__si_class_type_info@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new[](unsigned long)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak_hard()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::basic_streambuf(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned short@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::resize(unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char const*@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ctype<char>::_M_widen_init() const@GLIBCXX_3.4.11'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_invalid_argument(char const*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::operator=(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_free_exception@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::notify_one()@GLIBCXX_3.4.11'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::~Init()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_pure_virtual@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::flush()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__class_type_info@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_rethrow@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_fstream<char, std::char_traits<char> >::~basic_fstream()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::compare(char const*) const@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::system_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Hash_bytes(void const*, unsigned long, unsigned long)@CXXABI_1.3.5'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long long>(long long)@GLIBCXX_3.4.9'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char*@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned long, unsigned long, unsigned long) const@GLIBCXX_3.4.18'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long)@GLIBCXX_3.4.9'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::~ios_base()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::range_error::~range_error()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::~__basic_file()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_acquire@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<bool>(bool)@GLIBCXX_3.4.9'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::overflow_error@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::range_error@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_filebuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete[](void*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(unsigned long, char, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_transfer(std::__detail::_List_node_base*, std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::exception@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_M_destroy(std::allocator<wchar_t> const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream& std::istream::_M_extract<double>(double&)@GLIBCXX_3.4.9'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::basic_ifstream(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(std::string const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new(unsigned long)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::domain_error@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::put(char)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for int@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_alloc()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_thread_atexit@CXXABI_1.3.7'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int*@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::~basic_ifstream()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::Init()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::basic_filebuf()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::domain_error::~domain_error()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cerr@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::invalid_argument@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void*@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(std::string const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_rebalance_for_erase(std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_unhook()@GLIBCXX_3.4.15'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<char, std::char_traits<char> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::exception::~exception()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::is_open() const@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::swap(std::string&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::basic_streambuf(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::init(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_cast()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::clear(std::_Ios_Iostate)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::operator=(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long*@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete(void*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(int)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<wchar_t, std::char_traits<wchar_t> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::runtime_error@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long>(long)@GLIBCXX_3.4.9'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::get()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long long@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::out_of_range::~out_of_range()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::length_error::~length_error()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@GLIBCXX_3.4.9'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::invalid_argument::~invalid_argument()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::swap(std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cout@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long long>(unsigned long long)@GLIBCXX_3.4.9'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<void const*>(void const*)@GLIBCXX_3.4.9'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::underflow_error@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_allocate_exception@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void const*@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::init(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::reserve(unsigned long)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_begin_catch@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::open(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_M_sync(wchar_t*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::getline(char*, long, char)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::~condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::insert(unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned char@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::ios_base()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_out_of_range(char const*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::overflow_error::~overflow_error()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_length_error(char const*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_system_error(int)@GLIBCXX_3.4.11'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ofstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<double>(double)@GLIBCXX_3.4.9'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::operator=(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long long@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_release@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_throw@CXXABI_1.3'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::underflow_error::~underflow_error()@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::length_error@GLIBCXX_3.4'\n",
      "/home/capstone_student/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::~basic_filebuf()@GLIBCXX_3.4'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "# Initialize Trainer\n",
    "print(\"üîÑ Initializing trainer...\")\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "\n",
    "print(\"Trainer Initalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa02fe9e-065d-46db-851e-1238db347b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training...\n",
      "üîç Loading image from: color_img/color_img_53.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_53.json\n",
      "üìù Description: This is a solid yellow color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_64.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_64.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color white?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[8, 2, 1, 2]' is invalid for input of size 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start Fine-Tuning\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müöÄ Starting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Training complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Save Fine-Tuned Model\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/transformers/trainer.py:3698\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3698\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3703\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3704\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/transformers/trainer.py:3759\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3757\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3758\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3759\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3760\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1795\u001b[0m, in \u001b[0;36mQwen2_5_VLForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, rope_deltas, cache_position, second_per_grid_ts)\u001b[0m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixel_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1794\u001b[0m     pixel_values \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 1795\u001b[0m     image_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_thw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_grid_thw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1796\u001b[0m     n_image_tokens \u001b[38;5;241m=\u001b[39m (input_ids \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mimage_token_id)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1797\u001b[0m     n_image_features \u001b[38;5;241m=\u001b[39m image_embeds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:519\u001b[0m, in \u001b[0;36mQwen2_5_VisionTransformerPretrainedModel.forward\u001b[0;34m(self, hidden_states, grid_thw)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.Tensor` of shape `(seq_len, hidden_size)`):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03m    `torch.Tensor`: hidden_states.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    518\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(hidden_states)\n\u001b[0;32m--> 519\u001b[0m rotary_pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrot_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_thw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m window_index, cu_window_seqlens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_window_index(grid_thw)\n\u001b[1;32m    521\u001b[0m cu_window_seqlens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    522\u001b[0m     cu_window_seqlens,\n\u001b[1;32m    523\u001b[0m     device\u001b[38;5;241m=\u001b[39mhidden_states\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    524\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mgrid_thw\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mint32,\n\u001b[1;32m    525\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:441\u001b[0m, in \u001b[0;36mQwen2_5_VisionTransformerPretrainedModel.rot_pos_emb\u001b[0;34m(self, grid_thw)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, h, w \u001b[38;5;129;01min\u001b[39;00m grid_thw:\n\u001b[1;32m    440\u001b[0m     hpos_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(h)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, w)\n\u001b[0;32m--> 441\u001b[0m     hpos_ids \u001b[38;5;241m=\u001b[39m \u001b[43mhpos_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspatial_merge_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspatial_merge_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspatial_merge_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspatial_merge_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m     hpos_ids \u001b[38;5;241m=\u001b[39m hpos_ids\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    448\u001b[0m     hpos_ids \u001b[38;5;241m=\u001b[39m hpos_ids\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[8, 2, 1, 2]' is invalid for input of size 48"
     ]
    }
   ],
   "source": [
    "# Start Fine-Tuning\n",
    "print(\"üöÄ Starting training...\")\n",
    "trainer.train()\n",
    "print(\"‚úÖ Training complete!\")\n",
    "\n",
    "# Save Fine-Tuned Model\n",
    "print(f\"üíæ Saving fine-tuned model to {OUTPUT_DIR}...\")\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "processor.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"‚úÖ Model saved successfully in: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4edfe00a-d68b-43e2-b230-feb38a769448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading image from: color_img/color_img_64.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_64.json\n",
      "üìù Description: This is a solid white color image.\n",
      "‚ùì Question: Is this color white?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_31.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_31.json\n",
      "üìù Description: This is a solid black color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_93.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_93.json\n",
      "üìù Description: This is a solid cyan color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_79.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_79.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_38.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_38.json\n",
      "üìù Description: This is a solid lime color image.\n",
      "‚ùì Question: Is this color lime?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_81.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_81.json\n",
      "üìù Description: This is a solid gray color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_51.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_51.json\n",
      "üìù Description: This is a solid green color image.\n",
      "‚ùì Question: Is this color green?\n",
      "üí¨ Answer: Yes\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üîç Loading image from: color_img/color_img_3.png\n",
      "üîç Loading pixel values from: pixel_values/pixel_values_3.json\n",
      "üìù Description: This is a solid magenta color image.\n",
      "‚ùì Question: Is this color some other color?\n",
      "üí¨ Answer: No\n",
      "üì¶ Processor output keys: dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])\n",
      "üè∑Ô∏è Final labels dtype: torch.int64\n",
      "üè∑Ô∏è labels tensor shape: torch.Size([1, 1])\n",
      "üìè pixel_values tensor shape: torch.Size([1, 3, 224, 224])\n",
      "üî• pixel_values shape before forward pass: torch.Size([8, 1, 3, 224, 224])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# üö® Debugging forward pass\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müö® Error during forward pass!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1792\u001b[0m, in \u001b[0;36mQwen2_5_VLForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, rope_deltas, cache_position, second_per_grid_ts)\u001b[0m\n\u001b[1;32m   1789\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1792\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pixel_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1794\u001b[0m         pixel_values \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/sinarmas_project_flowchart/venv/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(f\"üî• pixel_values shape before forward pass: {batch['pixel_values'].shape}\")\n",
    "\n",
    "    # üö® Debugging forward pass\n",
    "    try:\n",
    "        outputs = model(**batch)\n",
    "    except RuntimeError as e:\n",
    "        print(\"üö® Error during forward pass!\")\n",
    "        print(\"üî• pixel_values shape:\", batch[\"pixel_values\"].shape)\n",
    "        print(\"üî• labels shape:\", batch[\"labels\"].shape)\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840cf9b-005b-4d52-8651-02526044275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass debug\n",
    "try:\n",
    "    outputs = model(**batch)\n",
    "except RuntimeError as e:\n",
    "    print(\"üö® Error during forward pass!\")\n",
    "    print(\"pixel_values shape:\", batch[\"pixel_values\"].shape)\n",
    "    print(\"labels shape:\", batch[\"labels\"].shape if \"labels\" in batch else \"No labels\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17e859-c2b6-4514-9c7a-881348397261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf9e37-77a1-411b-8588-d582d0a3c6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e19a4-e579-4a1c-8adb-95c424e80347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0b662-6a42-4a92-98e9-93d159d63009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e642df-0d36-4ad3-9155-600897544031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
